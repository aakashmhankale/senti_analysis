{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "<input>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-2-4f8da902e541>:76: DeprecationWarning: invalid escape sequence \\.\n",
      "  tweet=re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
      "<ipython-input-2-4f8da902e541>:77: DeprecationWarning: invalid escape sequence \\s\n",
      "  tweet=re.sub('@[^\\s]+','AT_USER',tweet)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\amhan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\n",
      "Requirement already satisfied: pytz in c:\\users\\amhan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\amhan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in c:\\users\\amhan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\amhan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: numpy>=1.7.1 in c:\\users\\amhan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\amhan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from matplotlib)\n",
      "{\"created_at\": \"Sat Apr 15 19:46:56 +0000 2017\", \"default_profile\": true, \"followers_count\": 5, \"friends_count\": 85, \"id\": 853333839824830464, \"lang\": \"en\", \"name\": \"Aakash\", \"profile_background_color\": \"F5F8FA\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/853333839824830464/1494374730\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/862096213113397248/GPubrQa5_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"aakashmhankale\"}\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "\n",
    "import twitter\n",
    "\n",
    "api=twitter.Api(consumer_key=\"KL2IfG4k5of9nJB0zrg39eO47\",\n",
    "               consumer_secret=\"0rFl7N2wMTecOyt4lgsBYHL6fgTJeC6HrTiDKO1QDXLEAnCW1I\",\n",
    "               access_token_key=\"853333839824830464-RYWlaPearvaJ9m9pqIFlbHIyfyLb6BB\",\n",
    "               access_token_secret=\"XtLqKwFhrDOqmjVHl2lyPKNvTruZZA8a3WiISwk6jMpjd\")\n",
    "\n",
    "print(api.VerifyCredentials())\n",
    "\n",
    "def createTestData(search_string):\n",
    "    try:\n",
    "        tweets_fetched=api.GetSearch(search_string,count=100)\n",
    "        print(\"Great! We fetched\"+str(len(tweets_fetched))+\"tweets fetched with the term\"+search_string+\"!!\")\n",
    "        return[{\"text\":status.text,\"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print(\"Sorry there was an error!!\")\n",
    "        return None\n",
    "search_string=input(\"Hi, There ! what are we searching for today?\")\n",
    "testData=createTestData(search_string)\n",
    "testData[0:9]\n",
    "\n",
    "def createLimitedTrainingCorpus(corpusFile,tweetDatafile):\n",
    "    import csv\n",
    "    corpus=[]\n",
    "    with open(corpusFile,\"r\") as csvfile:\n",
    "        lineReader = csv.reader(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for row in lineReader:\n",
    "            corpus.append({\"tweet_id\":row[2],\"label\":row[1],\"topic\":row[0]})\n",
    "\n",
    "    trainingData=[]\n",
    "    for label in [\"positive\",\"negative\"]:\n",
    "        i=1\n",
    "        for tweet in corpus:\n",
    "            if tweet[\"label\"]==label and i<=50:\n",
    "                try:\n",
    "                    status=api.GetStatus(tweet[\"tweet_id\"])\n",
    "                    print(\"Tweet Fetched\"+status.text)\n",
    "                    tweet[\"text\"]=status.text\n",
    "                    trainingData.append(tweet)\n",
    "                    i=i+1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    with open(tweetDataFile,\"w\") as csvfile:\n",
    "        linewriter=csv.writer(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for tweet in trainingData:\n",
    "            try:\n",
    "                linewriter.writerow([tweet[\"tweet_id\"],tweet[\"text\"],tweet[\"label\"],tweet[\"topic\"]])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return trainingData\n",
    "\n",
    "corpusFile=\"/Users/amhan/Desktop/Sentiment_analysis/corpus.csv\"\n",
    "tweetDataFile=\"/Users/amhan/Desktop/Sentiment_analysis/tweetDataFile.csv\"\n",
    "                              \n",
    "trainingData=createLimitedTrainingCorpus(corpusFile,tweetDataFile)                              \n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords=set(stopwords.words('english')+list(punctuation)+['AT_USER','URL'])\n",
    "    def processTweets(self,list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet[\"text\"]),tweet[\"label\"]))\n",
    "        return processedTweets\n",
    "\n",
    "    def _processTweet(self,tweet):\n",
    "        tweet=tweet.lower()\n",
    "        tweet=re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "        tweet=re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "        tweet=re.sub(r'#([^\\s]+)',r'\\1',tweet)\n",
    "        tweet=word_tokenize(tweet)\n",
    "        return [word for word in tweet if word not in self._stopwords]\n",
    "\n",
    "tweetProcessor=PreProcessTweets()\n",
    "ppTrainingData=tweetProcessor.processTweets(trainingData)\n",
    "ppTestData=tweetProcessor.processTweets(testData)\n",
    "\n",
    "ppTrainingData[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "\n",
    "def buildVocabulary(ppTrainingData):\n",
    "    all_words=[]\n",
    "    for (words,sentiment) in ppTrainingData:\n",
    "        all_words.extend(words)\n",
    "\n",
    "    wordlist=nltk.FreqDist(all_words)\n",
    "    \n",
    "    word_features=wordlist.keys()\n",
    "   \n",
    "    return word_features\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(tweet):\n",
    "    tweet_words=set(tweet)\n",
    "    features={}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word]=(word in tweet_words)\n",
    "\n",
    "    return features \n",
    "\n",
    "word_features = buildVocabulary(ppTrainingData)\n",
    "trainingFeatures=nltk.classify.apply_features(extract_features,ppTrainingData)\n",
    "\n",
    "NBayesClassifier=nltk.NaiveBayesClassifier.train(trainingFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "svmTrainingData=[' '.join(tweet[0]) for tweet in ppTrainingData]\n",
    "\n",
    "vectorizer=CountVectorizer(min_df=1)\n",
    "X=vectorizer.fit_transform(svmTrainingData).toarray()\n",
    "\n",
    "vocabulary=vectorizer.get_feature_names()\n",
    "\n",
    "swn_weights=[]\n",
    "\n",
    "for word in vocabulary:\n",
    "    try:\n",
    "        synset=list(swn.senti_synsets(word))\n",
    "        common_meaning =synset[0]\n",
    "\n",
    "        if common_meaning.pos_score()>common_meaning.neg_score():\n",
    "            weight=common_meaning.pos_score()\n",
    "        elif common_meaning.pos_score()<common_meaning.neg_score():\n",
    "            weight=-common_meaning.neg_score()\n",
    "        else: \n",
    "            weight=0\n",
    "    except: \n",
    "        weight=0\n",
    "    swn_weights.append(weight)\n",
    "\n",
    "\n",
    "swn_X=[]\n",
    "for row in X: \n",
    "    swn_X.append(np.multiply(row,np.array(swn_weights)))\n",
    "swn_X=np.vstack(swn_X)\n",
    "\n",
    "labels_to_array={\"positive\":1,\"negative\":2}\n",
    "labels=[labels_to_array[tweet[1]] for tweet in ppTrainingData]\n",
    "y=np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's now build our SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "SVMClassifier=SVC()\n",
    "SVMClassifier.fit(swn_X,y)\n",
    "\n",
    "NBResultLabels=[NBayesClassifier.classify(extract_features(tweet[0])) for tweet in ppTestData]\n",
    "\n",
    "# Now SVM \n",
    "SVMResultLabels=[]\n",
    "for tweet in ppTestData:\n",
    "    tweet_sentence=' '.join(tweet[0])\n",
    "    svmFeatures=np.multiply(vectorizer.transform([tweet_sentence]).toarray(),np.array(swn_weights))\n",
    "    SVMResultLabels.append(SVMClassifier.predict(svmFeatures)[0])\n",
    "\n",
    "if NBResultLabels.count('positive')>NBResultLabels.count('negative'):\n",
    "    print(\"NB Result Positive Sentiment\" + str(100*NBResultLabels.count('positive')/len(NBResultLabels))+\"%\")\n",
    "else: \n",
    "    print(\"NB Result Negative Sentiment\" + str(100*NBResultLabels.count('negative')/len(NBResultLabels))+\"%\")\n",
    "    \n",
    "    \n",
    "if SVMResultLabels.count(1)>SVMResultLabels.count(2):\n",
    "    print(\"SVM Result Positive Sentiment\" + str(100*SVMResultLabels.count(1)/len(SVMResultLabels))+\"%\")\n",
    "else: \n",
    "    print(\"SVM Result Negative Sentiment\" + str(100*SVMResultLabels.count(2)/len(SVMResultLabels))+\"%\")\n",
    "  \n",
    "  \n",
    "testData[0:10]\n",
    "\n",
    "NBResultLabels[0:10]\n",
    "\n",
    "SVMResultLabels[0:10]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
